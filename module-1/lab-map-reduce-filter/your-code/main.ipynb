{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reduce from functools, numpy and pandas\n",
    "\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up a words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = '../58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "#prophet[568:] - no hago print para que no salga una lista infinita\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet[568:578]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "def reference(x):\n",
    "    x = x.split(\"{\")\n",
    "    return x[0]\n",
    "\n",
    "reference(\"the{7}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nThis',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and\\nmost',\n",
       " 'other',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions\\nwhatsoever.',\n",
       " '',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms\\nof',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at\\nwww.gutenberg.org.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'located',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " \"you'll\\nhave\",\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'where',\n",
       " 'you',\n",
       " 'are',\n",
       " 'located',\n",
       " 'before',\n",
       " 'using\\nthis',\n",
       " 'ebook.\\n\\n\\n\\nTitle:',\n",
       " 'The',\n",
       " 'Prophet\\n\\nAuthor:',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nRelease',\n",
       " 'Date:',\n",
       " 'January',\n",
       " '1,',\n",
       " '2019',\n",
       " '[EBook',\n",
       " '#58585]\\nLast',\n",
       " 'Updated:',\n",
       " 'January',\n",
       " '3,',\n",
       " '2018\\n\\n\\nLanguage:',\n",
       " 'English\\n\\nCharacter',\n",
       " 'set',\n",
       " 'encoding:',\n",
       " 'UTF-8\\n\\n***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'THE',\n",
       " 'PROPHET',\n",
       " '***\\n\\n\\n\\n\\nProduced',\n",
       " 'by',\n",
       " 'David',\n",
       " 'Widger',\n",
       " 'from',\n",
       " 'page',\n",
       " 'images',\n",
       " 'generously\\nprovided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Internet',\n",
       " \"Archive\\n\\n\\nTranscriber's\",\n",
       " 'Note:',\n",
       " 'Page',\n",
       " 'numbers,',\n",
       " 'ie:',\n",
       " '',\n",
       " 'are',\n",
       " 'included',\n",
       " 'in',\n",
       " 'this\\nutf-8',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'For',\n",
       " 'those',\n",
       " 'wishing',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'text',\n",
       " 'file',\n",
       " 'unencumbered\\nwith',\n",
       " 'page',\n",
       " 'numbers',\n",
       " 'open',\n",
       " 'or',\n",
       " 'download',\n",
       " 'the',\n",
       " 'Latin-1',\n",
       " 'file',\n",
       " '58585-8.txt.\\n\\n\\n\\n\\n\\n\\n\\nTHE',\n",
       " 'PROPHET\\n\\nBy',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nNew',\n",
       " 'York:',\n",
       " 'Alfred',\n",
       " 'A.',\n",
       " 'Knopf\\n\\n1923\\n\\n_The',\n",
       " 'Twelve',\n",
       " 'Illustrations',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Volume\\nAre',\n",
       " 'Reproduced',\n",
       " 'From',\n",
       " 'Original',\n",
       " 'Drawings',\n",
       " 'By\\nThe',\n",
       " 'Author_\\n\\n\\n“His',\n",
       " 'power',\n",
       " 'came',\n",
       " 'from',\n",
       " 'some',\n",
       " 'great',\n",
       " 'reservoir\\nof',\n",
       " 'spiritual',\n",
       " 'life',\n",
       " 'else',\n",
       " 'it',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have\\nbeen',\n",
       " 'so',\n",
       " 'universal',\n",
       " 'and',\n",
       " 'so',\n",
       " 'potent,',\n",
       " 'but',\n",
       " 'the\\nmajesty',\n",
       " 'and',\n",
       " 'beauty',\n",
       " 'of',\n",
       " 'the',\n",
       " 'language',\n",
       " 'with\\nwhich',\n",
       " 'he',\n",
       " 'clothed',\n",
       " 'it',\n",
       " 'were',\n",
       " 'all',\n",
       " 'his',\n",
       " 'own?”\\n\\n--Claude',\n",
       " 'Bragdon\\n\\n\\nTHE',\n",
       " 'BOOKS',\n",
       " 'OF',\n",
       " 'KAHLIL',\n",
       " 'GIBRAN\\n\\nThe',\n",
       " 'Madman.',\n",
       " '1918',\n",
       " 'Twenty',\n",
       " 'Drawings.',\n",
       " '1919\\nThe',\n",
       " 'Forerunner.',\n",
       " '1920',\n",
       " 'The',\n",
       " 'Prophet.',\n",
       " '1923\\nSand',\n",
       " 'and',\n",
       " 'Foam.',\n",
       " '1926',\n",
       " 'Jesus',\n",
       " 'the',\n",
       " 'Son',\n",
       " 'of\\nMan.',\n",
       " '1928',\n",
       " 'The',\n",
       " 'Forth',\n",
       " 'Gods.',\n",
       " '1931',\n",
       " 'The\\nWanderer.',\n",
       " '1932',\n",
       " 'The',\n",
       " 'Garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Prophet\\n1933',\n",
       " 'Prose',\n",
       " 'Poems.',\n",
       " '1934',\n",
       " 'Nymphs',\n",
       " 'of',\n",
       " 'the\\nValley.',\n",
       " '1948\\n\\n\\n\\n\\nCONTENTS\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Coming',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Ship.......7\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Love.....................15\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Marriage.................19\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Children.................21\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Giving...................23\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Eating',\n",
       " 'and',\n",
       " 'Drinking......27\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Work.....................31\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Joy',\n",
       " 'and',\n",
       " 'Sorrow...........33\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Houses...................37\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Clothes..................41\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Buying',\n",
       " 'and',\n",
       " 'Selling.......43\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment.....45\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Laws.....................51\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Freedom..................55\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Reason',\n",
       " 'and',\n",
       " 'Passion.......57\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pain.....................60\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Self-Knowledge...........62\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Teaching.................64\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Friendship...............66\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Talking..................68\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Time.....................70\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Good',\n",
       " 'and',\n",
       " 'Evil............72\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Prayer...................76\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pleasure.................79\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Beauty...................83\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Religion.................87\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Death....................90\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Farewell................92\\n\\n\\n\\n\\nTHE',\n",
       " 'PROPHET\\n\\n|Almustafa,',\n",
       " 'the',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own\\nday,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'city\\nof',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to\\nreturn',\n",
       " 'and',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'isle',\n",
       " 'of\\nhis',\n",
       " 'birth.\\n\\nAnd',\n",
       " 'in',\n",
       " 'the',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'the',\n",
       " 'seventh\\nday',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'the',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he\\nclimbed',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'the',\n",
       " 'city',\n",
       " 'walls\\nand',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'and',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his\\nship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'the',\n",
       " 'mist.\\n\\nThen',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung\\nopen,',\n",
       " 'and',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'the',\n",
       " 'sea.\\nAnd',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'the\\nsilences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.\\n\\n*****\\n\\nBut',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'the',\n",
       " 'hill,',\n",
       " 'a',\n",
       " 'sadness\\ncame',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his\\nheart:\\n\\nHow',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'without\\nsorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'a',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'the\\nspirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " '',\n",
       " 'the',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent\\nwithin',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'and',\n",
       " 'long',\n",
       " 'were',\n",
       " 'the\\nnights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'and',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart\\nfrom',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'and',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without\\nregret?\\n\\nToo',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I\\nscattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'and',\n",
       " 'too',\n",
       " 'many\\nare',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk\\nnaked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'cannot\\nwithdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'a',\n",
       " 'burden',\n",
       " 'and\\nan',\n",
       " 'ache.\\n\\nIt',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this\\nday,',\n",
       " 'but',\n",
       " 'a',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own\\nhands.\\n\\nNor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,\\nbut',\n",
       " 'a',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'and\\nwith',\n",
       " 'thirst.\\n\\n*****\\n\\nYet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.\\n\\nThe',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her\\ncalls',\n",
       " 'me,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.\\n\\nFor',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'the',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in\\nthe',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'and',\n",
       " 'crystallize\\nand',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mould.\\n\\nFain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is\\nhere.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?\\n\\nA',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'tongue',\n",
       " 'and\\n',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone\\nmust',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'the',\n",
       " 'ether.\\n\\nAnd',\n",
       " 'alone',\n",
       " 'and',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'the\\neagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'the',\n",
       " 'sun.\\n\\n*****\\n\\nNow',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the\\nhill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'sea,\\nand',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'the\\nharbour,',\n",
       " 'and',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'the',\n",
       " 'mariners,\\nthe',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.\\n\\nAnd',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'and',\n",
       " 'he\\nsaid:\\n\\nSons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of\\nthe',\n",
       " 'tides,\\n\\nHow',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.\\nAnd',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which\\nis',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.\\n\\nReady',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'and',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with\\nsails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'the',\n",
       " 'wind.\\n\\nOnly',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in\\nthis',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look\\ncast',\n",
       " 'backward,\\n\\nAnd',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'a\\nseafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " '',\n",
       " 'you,\\nvast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,\\n\\nWho',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'the\\nriver',\n",
       " 'and',\n",
       " 'the',\n",
       " 'stream,\\n\\nOnly',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream\\nmake,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,\\n\\nAnd',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'a\\nboundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'a',\n",
       " 'boundless',\n",
       " 'ocean.\\n\\n*****\\n\\nAnd',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "prophet_reference = list(map(reference,prophet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'beloved']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_break(x):\n",
    "    return x.rsplit(\"\\n\")\n",
    "\n",
    "line_break(\"the\\nbeloved\")\n",
    "\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_line = map(line_break, prophet_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "prophet_flat = [i for i in prophet_line]\n",
    "\n",
    "#para hacerlo todo de una sería: prophet_line = [e for i in (map(line_break, prophet_reference)) for e in i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['and', 'the', 'a', 'an']\n",
    "\n",
    "def word_filter(x):\n",
    "    return [False if x in word_list else True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'the', 'a', 'an', 'jahdn']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Part 1\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[True]\n"
     ]
    }
   ],
   "source": [
    "word_list = ['and', 'the', 'a', 'an']\n",
    "\n",
    "def word_filter_case(x):\n",
    "    return [False if x.casefold() in word_list else True]\n",
    "    \n",
    "print(word_filter_case(\"The\"))\n",
    "print(word_filter_case(\"the\"))   \n",
    "print(word_filter_case(\"b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Smith'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_space(a,b):\n",
    "    return a + \" \" + b\n",
    "\n",
    "concat_space('John', 'Smith')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_space(a,b):\n",
    "    return lambda a,b:  a + \" \"+ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'functools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-9b0850540d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Your code here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprophet_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprophet_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'functools' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_string = functools.reduce(concat_space, prophet_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will load a dataset below and then write a function that will perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "# The dataset below contains information about pollution from PM2.5 particles in Beijing \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "pm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    return x/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "pm25[\"Iws\"]= hourly(pm25[\"Iws\"])\n",
    "pm25[\"Is\"]= hourly(pm25[\"Is\"])\n",
    "pm25[\"Ir\"]= hourly(pm25[\"Ir\"])\n",
    "\n",
    "pm25_hourly = pm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-0d459c6082c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_sd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-0d459c6082c0>\u001b[0m in \u001b[0;36msample_sd\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_sd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_sd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[0;32m-> 1555\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m             )\n\u001b[1;32m   1557\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "def sample_sd(x):\n",
    "    return x.std() / np.arange(x)\n",
    "\n",
    "sample_sd(pd.Series([1,2,3,4]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
